{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KCuorRa1xH9o"
   },
   "outputs": [],
   "source": [
    " #Feature Engineering\n",
    "\n",
    "\n",
    "  # Clean and pre-process the text data.\n",
    "  # Define features for comparing the similarity of an answer text and a source text, and extract similarity features.\n",
    "  # Select \"good\" features, by analyzing the correlations between different features.\n",
    "  # Create train/test .csv/.txt files that hold the relevant features and class labels for train/test data points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RQRtCQCMxH9u"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import operator \n",
    "import re\n",
    "import sys\n",
    "\n",
    "from adaptnlp import (\n",
    "    EasyTokenTagger,\n",
    "    EasySequenceClassifier,\n",
    "    EasyQuestionAnswering,\n",
    "    EasySummarizer,\n",
    "    EasyTranslator,\n",
    "    EasyDocumentEmbeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gqPAwYKfxH9x",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\swcam\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     C:\\Users\\swcam\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     C:\\Users\\swcam\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n"
    }
   ],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas, xgboost, numpy, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "import string\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "\n",
    "from featurefunctions import create_text_column, features,normalized_features,count_features,tfidf_features,tfidf_ngram_features,tfidf_ngram_chars,ling_feature_vec,all_count_features,all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v1GinESHxH92"
   },
   "source": [
    "## Import Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DvvEAtxuxH93"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     label                                           response  \\\n0  SARCASM  @USER @USER @USER I don't get this .. obviousl...   \n1  SARCASM  @USER @USER trying to protest about . Talking ...   \n\n                                           context/0  \\\n0  A minor child deserves privacy and should be k...   \n1  @USER @USER Why is he a loser ? He's just a Pr...   \n\n                                           context/1 context/2 context/3  \\\n0  @USER If your child isn't named Barron ... #Be...       NaN       NaN   \n1  @USER @USER having to make up excuses of why y...       NaN       NaN   \n\n  context/4 context/5 context/6 context/7  ... context/10 context/11  \\\n0       NaN       NaN       NaN       NaN  ...        NaN        NaN   \n1       NaN       NaN       NaN       NaN  ...        NaN        NaN   \n\n  context/12 context/13 context/14 context/15 context/16 context/17  \\\n0        NaN        NaN        NaN        NaN        NaN        NaN   \n1        NaN        NaN        NaN        NaN        NaN        NaN   \n\n  context/18 context/19  \n0        NaN        NaN  \n1        NaN        NaN  \n\n[2 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>response</th>\n      <th>context/0</th>\n      <th>context/1</th>\n      <th>context/2</th>\n      <th>context/3</th>\n      <th>context/4</th>\n      <th>context/5</th>\n      <th>context/6</th>\n      <th>context/7</th>\n      <th>...</th>\n      <th>context/10</th>\n      <th>context/11</th>\n      <th>context/12</th>\n      <th>context/13</th>\n      <th>context/14</th>\n      <th>context/15</th>\n      <th>context/16</th>\n      <th>context/17</th>\n      <th>context/18</th>\n      <th>context/19</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SARCASM</td>\n      <td>@USER @USER @USER I don't get this .. obviousl...</td>\n      <td>A minor child deserves privacy and should be k...</td>\n      <td>@USER If your child isn't named Barron ... #Be...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SARCASM</td>\n      <td>@USER @USER trying to protest about . Talking ...</td>\n      <td>@USER @USER Why is he a loser ? He's just a Pr...</td>\n      <td>@USER @USER having to make up excuses of why y...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 22 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "##TODO\n",
    "\n",
    "csv_file = '/Users/swcam/Documents/Github/Sarcasm/SarcasmTwitterTraining.csv'\n",
    "\n",
    "#'/Users/swcam/Documents/Github/Sarcasm/SarcasmTwitterTraining.csv'\n",
    "#csv_file = '/content/drive/My Drive/Colab Notebooks/Novetta_Disinformation/News_dataset/total_text_data.csv' \n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# print out the first few rows of data info\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pRj54-B_2qL-"
   },
   "outputs": [],
   "source": [
    "new_df = df.drop(['context/2','context/3','context/4','context/5','context/6','context/7','context/8','context/9','context/10','context/11','context/12','context/13','context/14','context/15','context/16','context/17'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[   3,   23,   43,    3,    9, 1829,    3,   23,  773,    9, 1513,   82,\n          200, 1565,    1]])"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-emotion\")\n",
    "\n",
    "model = AutoModelWithLMHead.from_pretrained(\"mrm8488/t5-base-finetuned-emotion\")\n",
    "\n",
    "def get_emotion(text):\n",
    "  input_ids = tokenizer.encode(text + '</s>', return_tensors='pt')\n",
    "\n",
    "  output = model.generate(input_ids=input_ids,\n",
    "               max_length=2)\n",
    "\n",
    "  dec = [tokenizer.decode(ids) for ids in output]\n",
    "  label = dec[0]\n",
    "  return input_ids\n",
    "\n",
    "get_emotion(\"i feel as if i havent blogged in ages are at least truly blogged i am doing an update cute\") # Output: 'joy'\n",
    "\n",
    "get_emotion(\"i have a feeling i kinda lost my best friend\") # Output: 'sadness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sadness'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-emotion\")\n",
    "\n",
    "model = AutoModelWithLMHead.from_pretrained(\"mrm8488/t5-base-finetuned-emotion\")\n",
    "\n",
    "def get_emotion_label(text):\n",
    "  input_ids = tokenizer.encode(text + '</s>', return_tensors='pt')\n",
    "\n",
    "  output = model.generate(input_ids=input_ids,\n",
    "               max_length=2)\n",
    "\n",
    "  dec = [tokenizer.decode(ids) for ids in output]\n",
    "  label = dec[0]\n",
    "  return label\n",
    "\n",
    "get_emotion_label(\"i feel as if i havent blogged in ages are at least truly blogged i am doing an update cute\") # Output: 'joy'\n",
    "\n",
    "get_emotion_label(\"i have a feeling i kinda lost my best friend\") # Output: 'sadness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def get_cosine_similarity(feature_vec_1,feature_vec_2):\n",
    "    return cosine_similarity(feature_vec_1.reshape(1, -1), feature_vec_2.reshape(1, -1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(text1, text2):\n",
    "    # Turns text into emotional tensors\n",
    "    tensor1 = get_emotion(text1)\n",
    "    tensor2 = get_emotion(text2)\n",
    "    \n",
    "    # Turns emotional tensors into numpy array\n",
    "    Vector_1 = numpy.array(tensor1)\n",
    "    Vector_2 = numpy.array(tensor2)\n",
    "    \n",
    "    #pads lower array with zeros to match higher array\n",
    "    if Vector_1.size >= Vector_2.size:\n",
    "        vA = Vector_1\n",
    "        vB = Vector_2\n",
    "        result = np.zeros(vA.shape)\n",
    "        result[:vB.shape[0],:vB.shape[1]] = vB\n",
    "        vC = vA\n",
    "    elif Vector_1.size <= Vector_2.size:\n",
    "        vB = Vector_2\n",
    "        vA = Vector_1\n",
    "        result = np.zeros(vB.shape)\n",
    "        result[:vA.shape[0],:vA.shape[1]]= vA\n",
    "        vC = vB\n",
    "    return vC, result\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = '@USER @USER trying to protest about . Talking about him and his labels and they label themselves WTF does that make em ?'\n",
    "text1 = 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'get_emotion_label' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a317a5257993>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0memotion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_emotion_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'get_emotion_label' is not defined"
     ]
    }
   ],
   "source": [
    "emotion = get_emotion_label(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = get_vectors(text2,text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarities = get_cosine_similarity(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2694203211894635\n"
     ]
    }
   ],
   "source": [
    "print(cosine_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating lists to keep pos, neu, neg, and compound scores --- later to be used to create a dataframe\n",
    "response_sent = []\n",
    "\n",
    "\n",
    "\n",
    "# extracting vader scores for each entry in the data\n",
    "# (we're not using context yet.)\n",
    "# note that the compound score is rescaled to the [0,1] range\n",
    "# some classiifers don't take negative values (e.g., MultinomialNB)\n",
    "\n",
    "for row in new_df[\"response\"]:\n",
    "    sentiment = get_emotion_label(row)\n",
    "  \n",
    "    response_sent.append(sentiment)\n",
    "\n",
    "\n",
    "##Create feature vector \n",
    "new_df[\"Response_emotion\"] = response_sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating lists to keep pos, neu, neg, and compound scores --- later to be used to create a dataframe\n",
    "context_sent = []\n",
    "\n",
    "\n",
    "\n",
    "# extracting vader scores for each entry in the data\n",
    "# (we're not using context yet.)\n",
    "# note that the compound score is rescaled to the [0,1] range\n",
    "# some classiifers don't take negative values (e.g., MultinomialNB)\n",
    "\n",
    "for row in new_df[\"context/0\"]:\n",
    "    if row == 0:\n",
    "        \n",
    "        sentiment = 'NaN'\n",
    "  \n",
    "        context_sent.append(sentiment)\n",
    "    else:\n",
    "        \n",
    "        sentiment = get_emotion_label(row)\n",
    "        context_sent.append(sentiment)\n",
    "        \n",
    "\n",
    "\n",
    "##Create feature vector \n",
    "new_df[\"context0_sentiment\"] = context_sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Should Theoretically work as long as get_vectors function is working properly \n",
    "\n",
    "\n",
    "Emotional_sim = []\n",
    "for row_a in new_df['response']:\n",
    "    if row_a == 0:\n",
    "        row_a = 'NaN'\n",
    "    else:\n",
    "        row_a = row_a\n",
    "            \n",
    "    for row_b in new_df['context/0']:\n",
    "        if row_b == 0:\n",
    "            row_b = 'NaN'\n",
    "        else:\n",
    "            row_b = row_b\n",
    "        \n",
    "        \n",
    "        text1 = row_a\n",
    "        text2 = row_b\n",
    "        \n",
    "    \n",
    "        a,b = get_vectors(text1,text2)\n",
    "        cosine_similarities = get_cosine_similarity(a,b)\n",
    "        Emotional_sim.append(cosine_similarities)\n",
    "    \n",
    "new_df[\"Emotional_sim_response/context/0\"] = Emotional_sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>response</th>\n",
       "      <th>context/0</th>\n",
       "      <th>context/1</th>\n",
       "      <th>context/18</th>\n",
       "      <th>context/19</th>\n",
       "      <th>Response_emotion</th>\n",
       "      <th>context0_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER @USER I don't get this .. obviousl...</td>\n",
       "      <td>A minor child deserves privacy and should be k...</td>\n",
       "      <td>@USER If your child isn't named Barron ... #Be...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>joy</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER trying to protest about . Talking ...</td>\n",
       "      <td>@USER @USER Why is he a loser ? He's just a Pr...</td>\n",
       "      <td>@USER @USER having to make up excuses of why y...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>anger</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER @USER He makes an insane about of ...</td>\n",
       "      <td>Donald J . Trump is guilty as charged . The ev...</td>\n",
       "      <td>@USER I ’ ll remember to not support you at th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>anger</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER Meanwhile Trump won't even release...</td>\n",
       "      <td>Jamie Raskin tanked Doug Collins . Collins loo...</td>\n",
       "      <td>@USER But not half as stupid as Schiff looks ....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>anger</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER Pretty Sure the Anti-Lincoln Crowd...</td>\n",
       "      <td>Man ... y ’ all gone “ both sides ” the apocal...</td>\n",
       "      <td>@USER They already did . Obama said many times...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>anger</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                           response  \\\n",
       "0  SARCASM  @USER @USER @USER I don't get this .. obviousl...   \n",
       "1  SARCASM  @USER @USER trying to protest about . Talking ...   \n",
       "2  SARCASM  @USER @USER @USER He makes an insane about of ...   \n",
       "3  SARCASM  @USER @USER Meanwhile Trump won't even release...   \n",
       "4  SARCASM  @USER @USER Pretty Sure the Anti-Lincoln Crowd...   \n",
       "\n",
       "                                           context/0  \\\n",
       "0  A minor child deserves privacy and should be k...   \n",
       "1  @USER @USER Why is he a loser ? He's just a Pr...   \n",
       "2  Donald J . Trump is guilty as charged . The ev...   \n",
       "3  Jamie Raskin tanked Doug Collins . Collins loo...   \n",
       "4  Man ... y ’ all gone “ both sides ” the apocal...   \n",
       "\n",
       "                                           context/1 context/18 context/19  \\\n",
       "0  @USER If your child isn't named Barron ... #Be...        NaN        NaN   \n",
       "1  @USER @USER having to make up excuses of why y...        NaN        NaN   \n",
       "2  @USER I ’ ll remember to not support you at th...        NaN        NaN   \n",
       "3  @USER But not half as stupid as Schiff looks ....        NaN        NaN   \n",
       "4  @USER They already did . Obama said many times...        NaN        NaN   \n",
       "\n",
       "  Response_emotion context0_sentiment  \n",
       "0              joy            sadness  \n",
       "1            anger            sadness  \n",
       "2            anger              anger  \n",
       "3            anger            sadness  \n",
       "4            anger            sadness  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotional Similiarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-77b6f56cc42a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mEmotional_sim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcosine_similarities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mnew_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Emotional_sim_response/context/0\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEmotional_sim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2937\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2938\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2940\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2999\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3000\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3001\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3002\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3635\u001b[0m             \u001b[1;31m# turn me into an ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3636\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3637\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3638\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[1;34m(data, index, copy)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Length of values does not match length of index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "### Should Theoretically work as long as get_vectors function is working properly \n",
    "\n",
    "\n",
    "Emotional_sim = []\n",
    "for row_a in new_df['response']:\n",
    "    if row_a == 0:\n",
    "        row_a = 'NaN'\n",
    "    else:\n",
    "        row_a = row_a\n",
    "            \n",
    "    for row_b in new_df['context/0']:\n",
    "        if row_b == 0:\n",
    "            row_b = 'NaN'\n",
    "        else:\n",
    "            row_b = row_b\n",
    "        \n",
    "        \n",
    "        text1 = row_a\n",
    "        text2 = row_b\n",
    "        \n",
    "    \n",
    "        if text1 or text2 == 'NaN':\n",
    "            cosine_similarities = 'NaN'\n",
    "            Emotional_sim.append(cosine_similarities)\n",
    "        \n",
    "        else:\n",
    "            a,b = get_vectors(text1,text2)\n",
    "            cosine_similarities = get_cosine_similarity(a,b)\n",
    "            Emotional_sim.append(cosine_similarities)\n",
    "    \n",
    "new_df[\"Emotional_sim_response/context/0\"] = Emotional_sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>response</th>\n",
       "      <th>context/0</th>\n",
       "      <th>context/1</th>\n",
       "      <th>context/18</th>\n",
       "      <th>context/19</th>\n",
       "      <th>Emotional_sim_response/context/0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER @USER I don't get this .. obviousl...</td>\n",
       "      <td>A minor child deserves privacy and should be k...</td>\n",
       "      <td>@USER If your child isn't named Barron ... #Be...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER trying to protest about . Talking ...</td>\n",
       "      <td>@USER @USER Why is he a loser ? He's just a Pr...</td>\n",
       "      <td>@USER @USER having to make up excuses of why y...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER @USER He makes an insane about of ...</td>\n",
       "      <td>Donald J . Trump is guilty as charged . The ev...</td>\n",
       "      <td>@USER I ’ ll remember to not support you at th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER Meanwhile Trump won't even release...</td>\n",
       "      <td>Jamie Raskin tanked Doug Collins . Collins loo...</td>\n",
       "      <td>@USER But not half as stupid as Schiff looks ....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER Pretty Sure the Anti-Lincoln Crowd...</td>\n",
       "      <td>Man ... y ’ all gone “ both sides ” the apocal...</td>\n",
       "      <td>@USER They already did . Obama said many times...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                           response  \\\n",
       "0  SARCASM  @USER @USER @USER I don't get this .. obviousl...   \n",
       "1  SARCASM  @USER @USER trying to protest about . Talking ...   \n",
       "2  SARCASM  @USER @USER @USER He makes an insane about of ...   \n",
       "3  SARCASM  @USER @USER Meanwhile Trump won't even release...   \n",
       "4  SARCASM  @USER @USER Pretty Sure the Anti-Lincoln Crowd...   \n",
       "\n",
       "                                           context/0  \\\n",
       "0  A minor child deserves privacy and should be k...   \n",
       "1  @USER @USER Why is he a loser ? He's just a Pr...   \n",
       "2  Donald J . Trump is guilty as charged . The ev...   \n",
       "3  Jamie Raskin tanked Doug Collins . Collins loo...   \n",
       "4  Man ... y ’ all gone “ both sides ” the apocal...   \n",
       "\n",
       "                                           context/1 context/18 context/19  \\\n",
       "0  @USER If your child isn't named Barron ... #Be...        NaN        NaN   \n",
       "1  @USER @USER having to make up excuses of why y...        NaN        NaN   \n",
       "2  @USER I ’ ll remember to not support you at th...        NaN        NaN   \n",
       "3  @USER But not half as stupid as Schiff looks ....        NaN        NaN   \n",
       "4  @USER They already did . Obama said many times...        NaN        NaN   \n",
       "\n",
       "  Emotional_sim_response/context/0  \n",
       "0                              NaN  \n",
       "1                              NaN  \n",
       "2                              NaN  \n",
       "3                              NaN  \n",
       "4                              NaN  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"Emotional_similiarity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Response_sentiment</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>anger</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>fear</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>joy</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>love</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>sadness</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>surprise</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>anger</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>fear</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>joy</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>love</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>sadness</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>surprise</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label Response_sentiment  counts\n",
       "0   NOT_SARCASM              anger     221\n",
       "1   NOT_SARCASM               fear      42\n",
       "2   NOT_SARCASM                joy     481\n",
       "3   NOT_SARCASM               love      25\n",
       "4   NOT_SARCASM            sadness     125\n",
       "5   NOT_SARCASM           surprise       6\n",
       "6       SARCASM              anger     340\n",
       "7       SARCASM               fear      49\n",
       "8       SARCASM                joy     380\n",
       "9       SARCASM               love      12\n",
       "10      SARCASM            sadness      97\n",
       "11      SARCASM           surprise      22"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['label', 'Response_sentiment']).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Synthetic_CSV_Fullset_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}