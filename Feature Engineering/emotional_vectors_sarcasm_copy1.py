# -*- coding: utf-8 -*-
"""Emotional_vectors_sarcasm-Copy1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tybPkOZiWcpJQz6on87MbtaXeDN08bhr
"""

#Feature Engineering


  # Clean and pre-process the text data.
  # Define features for comparing the similarity of an answer text and a source text, and extract similarity features.
  # Select "good" features, by analyzing the correlations between different features.
  # Create train/test .csv/.txt files that hold the relevant features and class labels for train/test data points.

import pandas as pd
import numpy as np
import os
import operator 
import re
import sys

import pandas, xgboost, numpy, textblob, string
from keras.preprocessing import text, sequence
from keras import layers, models, optimizers
import spacy
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize, sent_tokenize, RegexpTokenizer
from nltk.stem import PorterStemmer
from collections import Counter
import string
from scipy.sparse import hstack

"""## Import Data"""

##TODO

csv_file = '/Users/swcam/Documents/Github/Sarcasm/SarcasmTwitterTraining.csv'

#'/Users/swcam/Documents/Github/Sarcasm/SarcasmTwitterTraining.csv'
#csv_file = '/content/drive/My Drive/Colab Notebooks/Novetta_Disinformation/News_dataset/total_text_data.csv' 
df = pd.read_csv(csv_file)

# print out the first few rows of data info
df.head(2)

new_df = df.drop(['context/2','context/3','context/4','context/5','context/6','context/7','context/8','context/9','context/10','context/11','context/12','context/13','context/14','context/15','context/16','context/17'], axis=1)





## Function to get Emotion Vectors
from transformers import AutoTokenizer, AutoModelWithLMHead

tokenizer = AutoTokenizer.from_pretrained("mrm8488/t5-base-finetuned-emotion")

model = AutoModelWithLMHead.from_pretrained("mrm8488/t5-base-finetuned-emotion")

def get_emotion(text):
  input_ids = tokenizer.encode(text + '</s>', return_tensors='pt')

  output = model.generate(input_ids=input_ids,
               max_length=2)

  dec = [tokenizer.decode(ids) for ids in output]
  label = dec[0]
  return input_ids

#Function to get Emotion labels

from transformers import AutoTokenizer, AutoModelWithLMHead

tokenizer = AutoTokenizer.from_pretrained("mrm8488/t5-base-finetuned-emotion")

model = AutoModelWithLMHead.from_pretrained("mrm8488/t5-base-finetuned-emotion")

def get_emotion_label(text):
  input_ids = tokenizer.encode(text + '</s>', return_tensors='pt')

  output = model.generate(input_ids=input_ids,
               max_length=2)

  dec = [tokenizer.decode(ids) for ids in output]
  label = dec[0]
  return label

## Function for Cosine Similarity 

from sklearn.metrics.pairwise import cosine_similarity
def get_cosine_similarity(feature_vec_1,feature_vec_2):
    return cosine_similarity(feature_vec_1.reshape(1, -1), feature_vec_2.reshape(1, -1))[0][0]

## Function to get Equal length Vectors

def get_vectors(text1, text2):
    # Turns text into emotional tensors
    tensor1 = get_emotion(text1)
    tensor2 = get_emotion(text2)
    
    # Turns emotional tensors into numpy array
    Vector_1 = numpy.array(tensor1)
    Vector_2 = numpy.array(tensor2)
    
    #pads lower array with zeros to match higher array
    if Vector_1.size >= Vector_2.size:
        vA = Vector_1
        vB = Vector_2
        result = np.zeros(vA.shape)
        result[:vB.shape[0],:vB.shape[1]] = vB
        vC = vA
    elif Vector_1.size <= Vector_2.size:
        vB = Vector_2
        vA = Vector_1
        result = np.zeros(vB.shape)
        result[:vA.shape[0],:vA.shape[1]]= vA
        vC = vB
    return vC, result

"""# Emotion function test"""

text2 = '@USER @USER trying to protest about . Talking about him and his labels and they label themselves WTF does that make em ?'
text1 = 'NaN'

a,b = get_vectors(text2,text1)

cosine_similarities = get_cosine_similarity(a,b)

print(cosine_similarities)

#Use this to attache emotion label to response
response_sent = []



for row in new_df["response"]:
    sentiment = get_emotion_label(row)
  
    response_sent.append(sentiment)


##Create feature vector 
new_df["Response_emotion"] = response_sent

## Use this to attach emotion label to context
context_sent = []





for row in new_df["context/0"]:
    if row == 0:
        
        sentiment = 'NaN'
  
        context_sent.append(sentiment)
    else:
        
        sentiment = get_emotion_label(row)
        context_sent.append(sentiment)
        


##Create feature vector 
new_df["context0_emotion"] = context_sent

new_df.head()

"""# Emotional Similiarity"""

### Should Theoretically work as long as get_vectors function is working properly 
## It is best to try with a small subset

Emotional_sim = []
for row_a in new_df['response']:
    if row_a == 0:
        row_a = 'NaN'
    else:
        row_a = row_a
            
    for row_b in new_df['context/0']:
        if row_b == 0:
            row_b = 'NaN'
        else:
            row_b = row_b
        
        
        text1 = row_a
        text2 = row_b
        
    
        a,b = get_vectors(text1,text2)
        cosine_similarities = get_cosine_similarity(a,b)
        Emotional_sim.append(cosine_similarities)
    
new_df["Emotional_sim_response/context/0"] = Emotional_sim

new_df.head()

df.groupby(['label', 'Response_sentiment']).size().reset_index(name='counts')

new_df.to_csv("Emotional_similiarity.csv")

