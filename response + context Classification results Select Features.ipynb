



{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO\n",
    "\n",
    "csv_file = '/Users/swcam/Documents/GitHub/Sarcasm/Final_data/liwc_response_context_train.csv'\n",
    "#csv_file = '/Users/swcam/Documents/GitHub/Sarcasm/Final_Features_train_data'\n",
    "Train_df = pd.read_csv(csv_file)\n",
    "Train_df = Train_df.loc[:, ~Train_df.columns.str.contains('^Unnamed')]\n",
    "# print out the first few rows of data info\n",
    "Train_df.head(5)\n",
    "\n",
    "#These are the most useful features per SHAP \n",
    "\n",
    "\n",
    "##ALL\n",
    "#Train_df_select = Train_df[['vader_compound','vader_pos','Emotional_sim_response/context/0','you','noun_count_percent','upper_case_word_count','char_count','adv_count_percent','time','context1_emotion','incl','cos_sim','pro_count_percent','ipron','vader_neg','context0_emotion','dom_diff_c0_resp','Emotional_sim_response/context/1','response_emotion','aro_diff_c1_resp']].copy()\n",
    "\n",
    "Train_df_select = Train_df[['time', 'achieve','article','preps','relativ','funct']]\n",
    "##Below per SHAP on only the Training data\n",
    "#Train_df_select = Train_df[['vader_compound','pro_count_percent','vader_pos','vader_neg','context0_emotion','noun_count_percent','time','char_count','adv_count_percent','you','cos_sim1','vader_neu','adj_count_percent','cos_sim','context1_emotion','pronoun','incl','discrep','upper_case_word_count','negate','val_diff_c1_resp','aro_diff_c1_resp','dom_diff_c1_resp']].copy()\n",
    "\n",
    "##Below per SHAP on the TEST and Trainind data\n",
    "#Train_df_select = Train_df[['friend','vader_compound','response_emotion','word_density','cos_sim','char_count','context0_emotion','vader_neg','relativ','ingest','cos_sim1','humans','punctuation_count','context1_emotion','upper_case_word_count','i','ppron','pro_count_percent','cogmech','article']]\n",
    "##Top few\n",
    "#Train_df_select = Train_df[['vader_compound', 'context0_sentiment', 'word_density','posemo','work','cos_sim1','you','ppron','Response_emotion','ipron','vader_neu','cos_sim','punctuation_count','char_count','negemo','noun_count_percent']].copy()\n",
    "#Train_df_select = Train_df[['vader_compound','response_emotion','word_density','cos_sim','context0_emotion','vader_neg','cos_sim1','humans','punctuation_count','context1_emotion','upper_case_word_count','ppron','pro_count_percent','article']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO\n",
    "\n",
    "csv_file = '/Users/swcam/Documents/GitHub/Sarcasm/Final_data/liwc_response_context_test.csv'\n",
    "#csv_file = '/Users/swcam/Documents/GitHub/Sarcasm/Final_Features_test_data'\n",
    "Test_df = pd.read_csv(csv_file)\n",
    "Test_df = Test_df.loc[:, ~Test_df.columns.str.contains('^Unnamed')]\n",
    "# print out the first few rows of data info\n",
    "Test_df.head(5)\n",
    "\n",
    "# These are the most useful features per SHAP\n",
    "#ALL\n",
    "#Test_df_select = Test_df[['vader_compound','pro_count_percent','vader_pos','vader_neg','context0_emotion','noun_count_percent','time','char_count','adv_count_percent','you','cos_sim1','vader_neu','adj_count_percent','cos_sim','context1_emotion','pronoun','incl','discrep','upper_case_word_count','negate']].copy()\n",
    "\n",
    "## PEr SHAP on just the TRAIN data\n",
    "#Test_df_select = Test_df[['vader_compound','vader_pos','Emotional_sim_response/context/0','you','noun_count_percent','upper_case_word_count','char_count','adv_count_percent','time','context1_emotion','incl','cos_sim','pro_count_percent','ipron','vader_neg','context0_emotion','dom_diff_c0_resp','Emotional_sim_response/context/1','response_emotion','aro_diff_c1_resp']].copy()\n",
    "Test_df_select = Test_df[['time', 'achieve','article','preps','relativ','funct']]\n",
    "## Per SHAP on the TEST and TRAIN data\n",
    "#Test_df_select = Test_df[['friend','vader_compound','response_emotion','word_density','cos_sim','char_count','context0_emotion','vader_neg','relativ','ingest','cos_sim1','humans','punctuation_count','context1_emotion','upper_case_word_count','i','ppron','pro_count_percent','cogmech','article']]\n",
    "\n",
    "#Test_df_select = Test_df[['vader_compound','response_emotion','word_density','cos_sim','context0_emotion','vader_neg','cos_sim1','humans','punctuation_count','context1_emotion','upper_case_word_count','ppron','pro_count_percent','article']]\n",
    "\n",
    "##Top few\n",
    "#Test_df_select = Test_df[['vader_compound', 'context0_sentiment', 'word_density','posemo','work','cos_sim1']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Train_df_select\n",
    "\n",
    "X_test= Test_df_select\n",
    "\n",
    "y_train= Train_df['label']\n",
    "\n",
    "y_test = Test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test['response_emotion'] = X_test['response_emotion'].astype('category').cat.codes\n",
    "X_test['context1_emotion'] = X_test['context1_emotion'].astype('category').cat.codes\n",
    "X_test['context0_emotion'] = X_test['context0_emotion'].astype('category').cat.codes\n",
    "\n",
    "\n",
    "\n",
    "X_train['context1_emotion'] = X_train['context1_emotion'].astype('category').cat.codes\n",
    "X_train['response_emotion'] = X_train['response_emotion'].astype('category').cat.codes\n",
    "X_train['context0_emotion'] = X_train['context0_emotion'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import preprocessing\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "# fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "    return metrics.accuracy_score(predictions, y_test),metrics.precision_score(predictions, y_test),metrics.recall_score(predictions, y_test),metrics.f1_score(predictions, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results on Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, :  A: 0.52 P: 0.6 R: 0.52 F1: 0.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "accuracy, precision, recall,f1  = train_model(naive_bayes.GaussianNB(), X_train, y_train, X_test)\n",
    "print (\"NB, : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random Forest:  A: 0.52 P: 0.45 R: 0.53 F1: 0.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "accuracy, precision, recall,fl  = train_model(RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0), X_train, y_train, X_test)\n",
    "print (\"random Forest: \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Svm:  A: 0.52 P: 0.45 R: 0.52 F1: 0.48\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "accuracy, precision, recall,f1  = train_model(svm.SVC(), X_train, y_train, X_test)\n",
    "print (\"Svm: \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:  A: 0.53 P: 0.49 R: 0.53 F1: 0.51\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "accuracy, precision, recall,f1  = train_model(LogisticRegression(random_state=0,max_iter=500), X_train, y_train, X_test)\n",
    "print (\"Logistic Regression: \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on Train data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0,max_iter=500),\n",
    "    GaussianNB(),\n",
    "    svm.SVC(),\n",
    "]\n",
    "CV = 10\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "  model_name = model.__class__.__name__\n",
    "  accuracies = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=CV)\n",
    "  for fold_idx, accuracy in enumerate(accuracies):\n",
    "    entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "import seaborn as sns\n",
    "sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
    "              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df.groupby('model_name').accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df.groupby('model_name').accuracy.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df.groupby('model_name').accuracy.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
