

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are 83 linguistic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>funct</th>\n",
       "      <th>auxverb</th>\n",
       "      <th>present</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>ipron</th>\n",
       "      <th>cogmech</th>\n",
       "      <th>certain</th>\n",
       "      <th>ppron</th>\n",
       "      <th>you</th>\n",
       "      <th>social</th>\n",
       "      <th>affect</th>\n",
       "      <th>posemo</th>\n",
       "      <th>conj</th>\n",
       "      <th>tentat</th>\n",
       "      <th>excl</th>\n",
       "      <th>future</th>\n",
       "      <th>discrep</th>\n",
       "      <th>past</th>\n",
       "      <th>motion</th>\n",
       "      <th>relativ</th>\n",
       "      <th>space</th>\n",
       "      <th>preps</th>\n",
       "      <th>incl</th>\n",
       "      <th>adverb</th>\n",
       "      <th>insight</th>\n",
       "      <th>shehe</th>\n",
       "      <th>achieve</th>\n",
       "      <th>negemo</th>\n",
       "      <th>anger</th>\n",
       "      <th>they</th>\n",
       "      <th>cause</th>\n",
       "      <th>article</th>\n",
       "      <th>money</th>\n",
       "      <th>work</th>\n",
       "      <th>percept</th>\n",
       "      <th>hear</th>\n",
       "      <th>swear</th>\n",
       "      <th>time</th>\n",
       "      <th>negate</th>\n",
       "      <th>leisure</th>\n",
       "      <th>death</th>\n",
       "      <th>number</th>\n",
       "      <th>see</th>\n",
       "      <th>sad</th>\n",
       "      <th>quant</th>\n",
       "      <th>anx</th>\n",
       "      <th>assent</th>\n",
       "      <th>bio</th>\n",
       "      <th>health</th>\n",
       "      <th>filler</th>\n",
       "      <th>body</th>\n",
       "      <th>friend</th>\n",
       "      <th>sexual</th>\n",
       "      <th>we</th>\n",
       "      <th>home</th>\n",
       "      <th>feel</th>\n",
       "      <th>inhib</th>\n",
       "      <th>humans</th>\n",
       "      <th>i</th>\n",
       "      <th>family</th>\n",
       "      <th>relig</th>\n",
       "      <th>nonfl</th>\n",
       "      <th>ingest</th>\n",
       "      <th>label</th>\n",
       "      <th>noun_count_percent</th>\n",
       "      <th>adj_count_percent</th>\n",
       "      <th>adv_count_percent</th>\n",
       "      <th>pro_count_percent</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>response</th>\n",
       "      <th>Response_emotion</th>\n",
       "      <th>valence_response</th>\n",
       "      <th>arousal_response</th>\n",
       "      <th>dominance_response</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>4.862069</td>\n",
       "      <td>0.167658</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.87530</td>\n",
       "      <td>I don't get this .. obviously you do car...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>6.222500</td>\n",
       "      <td>3.695000</td>\n",
       "      <td>5.965000</td>\n",
       "      <td>['I', 'do', \"n't\", 'get', 'this', '..', 'obvio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.11985</td>\n",
       "      <td>trying to protest about . Talking about hi...</td>\n",
       "      <td>anger</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>3.713333</td>\n",
       "      <td>5.733333</td>\n",
       "      <td>['trying', 'to', 'protest', 'about', '.', 'Tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>5.777778</td>\n",
       "      <td>0.320988</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.27130</td>\n",
       "      <td>He makes an insane about of money from t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>5.246667</td>\n",
       "      <td>5.223333</td>\n",
       "      <td>5.426667</td>\n",
       "      <td>['He', 'makes', 'an', 'insane', 'about', 'of',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>0.243056</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.24470</td>\n",
       "      <td>Meanwhile Trump won't even release his SAT...</td>\n",
       "      <td>anger</td>\n",
       "      <td>5.661111</td>\n",
       "      <td>4.428889</td>\n",
       "      <td>5.907778</td>\n",
       "      <td>['Meanwhile', 'Trump', 'wo', \"n't\", 'even', 'r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>5.575758</td>\n",
       "      <td>0.168962</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.83525</td>\n",
       "      <td>Pretty Sure the Anti-Lincoln Crowd Claimed...</td>\n",
       "      <td>joy</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>['Pretty', 'Sure', 'the', 'Anti-Lincoln', 'Cro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   verb  funct  auxverb  present  pronoun  ipron  cogmech  certain  ppron  \\\n",
       "0     7     13        3        5        5      1        6        1      4   \n",
       "1     2     11        1        2        5      1        3        0      4   \n",
       "2     1      5        0        1        0      0        1        0      0   \n",
       "3     3      9        1        0        4      0        2        1      4   \n",
       "4     0      5        0        0        0      0        0        0      0   \n",
       "\n",
       "   you  social  affect  posemo  conj  tentat  excl  future  discrep  past  \\\n",
       "0    3       4       2       2     2       1     1       1        1     1   \n",
       "1    0       4       1       0     2       0     0       0        0     0   \n",
       "2    0       0       0       0     0       0     0       0        0     0   \n",
       "3    0       5       1       0     1       0     0       0        0     3   \n",
       "4    0       0       0       0     0       0     0       0        0     0   \n",
       "\n",
       "   motion  relativ  space  preps  incl  adverb  insight  shehe  achieve  \\\n",
       "0       1        2      1      2     2       1        1      1        0   \n",
       "1       0        0      0      3     2       2        0      2        1   \n",
       "2       0        0      0      3     0       1        0      0        0   \n",
       "3       0        1      0      0     1       2        0      3        0   \n",
       "4       0        2      2      2     0       1        0      0        0   \n",
       "\n",
       "   negemo  anger  they  cause  article  money  work  percept  hear  swear  \\\n",
       "0       0      0     0      0        0      0     0        0     0      0   \n",
       "1       1      1     2      1        0      0     0        0     0      0   \n",
       "2       0      0     0      1        2      1     0        0     0      0   \n",
       "3       1      1     1      0        1      0     3        1     1      1   \n",
       "4       0      0     0      0        2      0     0        0     0      0   \n",
       "\n",
       "   time  negate  leisure  death  number  see  sad  quant  anx  assent  bio  \\\n",
       "0     0       0        0      0       0    0    0      0    0       0    0   \n",
       "1     0       0        0      0       0    0    0      0    0       0    0   \n",
       "2     0       0        0      0       0    0    0      0    0       0    0   \n",
       "3     1       0        0      0       0    0    0      0    0       0    0   \n",
       "4     0       0        0      0       0    0    0      0    0       0    0   \n",
       "\n",
       "   health  filler  body  friend  sexual  we  home  feel  inhib  humans  i  \\\n",
       "0       0       0     0       0       0   0     0     0      0       0  0   \n",
       "1       0       0     0       0       0   0     0     0      0       0  0   \n",
       "2       0       0     0       0       0   0     0     0      0       0  0   \n",
       "3       0       0     0       0       0   0     0     0      0       0  0   \n",
       "4       0       0     0       0       0   0     0     0      0       0  0   \n",
       "\n",
       "   family  relig  nonfl  ingest    label  noun_count_percent  \\\n",
       "0       0      0      0       0  SARCASM            0.310345   \n",
       "1       0      0      0       0  SARCASM            0.250000   \n",
       "2       0      0      0       0  SARCASM            0.055556   \n",
       "3       0      0      0       0  SARCASM            0.208333   \n",
       "4       0      0      0       0  SARCASM            0.060606   \n",
       "\n",
       "   adj_count_percent  adv_count_percent  pro_count_percent  char_count  \\\n",
       "0           0.034483           0.172414           0.172414    4.862069   \n",
       "1           0.000000           0.000000           0.166667    5.000000   \n",
       "2           0.000000           0.000000           0.055556    5.777778   \n",
       "3           0.041667           0.166667           0.166667    5.833333   \n",
       "4           0.030303           0.030303           0.030303    5.575758   \n",
       "\n",
       "   word_density  punctuation_count  upper_case_word_count  vader_pos  \\\n",
       "0      0.167658           0.379310               0.137931      0.204   \n",
       "1      0.208333           0.166667               0.125000      0.000   \n",
       "2      0.320988           0.333333               0.222222      0.000   \n",
       "3      0.243056           0.166667               0.125000      0.000   \n",
       "4      0.168962           0.393939               0.090909      0.193   \n",
       "\n",
       "   vader_neg  vader_neu  vader_compound  \\\n",
       "0      0.000      0.796         0.87530   \n",
       "1      0.256      0.744         0.11985   \n",
       "2      0.176      0.824         0.27130   \n",
       "3      0.130      0.870         0.24470   \n",
       "4      0.000      0.807         0.83525   \n",
       "\n",
       "                                            response Response_emotion  \\\n",
       "0        I don't get this .. obviously you do car...          sadness   \n",
       "1      trying to protest about . Talking about hi...            anger   \n",
       "2        He makes an insane about of money from t...            anger   \n",
       "3      Meanwhile Trump won't even release his SAT...            anger   \n",
       "4      Pretty Sure the Anti-Lincoln Crowd Claimed...              joy   \n",
       "\n",
       "   valence_response  arousal_response  dominance_response  \\\n",
       "0          6.222500          3.695000            5.965000   \n",
       "1          5.190000          3.713333            5.733333   \n",
       "2          5.246667          5.223333            5.426667   \n",
       "3          5.661111          4.428889            5.907778   \n",
       "4          5.000000          5.000000            5.000000   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  ['I', 'do', \"n't\", 'get', 'this', '..', 'obvio...  \n",
       "1  ['trying', 'to', 'protest', 'about', '.', 'Tal...  \n",
       "2  ['He', 'makes', 'an', 'insane', 'about', 'of',...  \n",
       "3  ['Meanwhile', 'Trump', 'wo', \"n't\", 'even', 'r...  \n",
       "4  ['Pretty', 'Sure', 'the', 'Anti-Lincoln', 'Cro...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TODO\n",
    "\n",
    "csv_file = '/Users/swcam/Documents/GitHub/Sarcasm/Final_data/liwc_response_train.csv'\n",
    "#csv_file = '/Users/swcam/Documents/GitHub/Sarcasm/Final_Features_train_data'\n",
    "Train_df = pd.read_csv(csv_file)\n",
    "Train_df = Train_df.loc[:, ~Train_df.columns.str.contains('^Unnamed')]\n",
    "# print out the first few rows of data info\n",
    "Train_df.head(5)\n",
    "\n",
    "#These are the most useful features per SHAP \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>relativ</th>\n",
       "      <th>funct</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>ipron</th>\n",
       "      <th>adverb</th>\n",
       "      <th>cogmech</th>\n",
       "      <th>excl</th>\n",
       "      <th>leisure</th>\n",
       "      <th>conj</th>\n",
       "      <th>incl</th>\n",
       "      <th>verb</th>\n",
       "      <th>past</th>\n",
       "      <th>social</th>\n",
       "      <th>ppron</th>\n",
       "      <th>i</th>\n",
       "      <th>cause</th>\n",
       "      <th>humans</th>\n",
       "      <th>certain</th>\n",
       "      <th>achieve</th>\n",
       "      <th>preps</th>\n",
       "      <th>tentat</th>\n",
       "      <th>space</th>\n",
       "      <th>affect</th>\n",
       "      <th>filler</th>\n",
       "      <th>posemo</th>\n",
       "      <th>present</th>\n",
       "      <th>they</th>\n",
       "      <th>shehe</th>\n",
       "      <th>negemo</th>\n",
       "      <th>anger</th>\n",
       "      <th>quant</th>\n",
       "      <th>auxverb</th>\n",
       "      <th>article</th>\n",
       "      <th>insight</th>\n",
       "      <th>work</th>\n",
       "      <th>you</th>\n",
       "      <th>motion</th>\n",
       "      <th>discrep</th>\n",
       "      <th>assent</th>\n",
       "      <th>inhib</th>\n",
       "      <th>home</th>\n",
       "      <th>percept</th>\n",
       "      <th>hear</th>\n",
       "      <th>anx</th>\n",
       "      <th>sad</th>\n",
       "      <th>see</th>\n",
       "      <th>money</th>\n",
       "      <th>negate</th>\n",
       "      <th>bio</th>\n",
       "      <th>health</th>\n",
       "      <th>sexual</th>\n",
       "      <th>nonfl</th>\n",
       "      <th>future</th>\n",
       "      <th>swear</th>\n",
       "      <th>ingest</th>\n",
       "      <th>feel</th>\n",
       "      <th>number</th>\n",
       "      <th>body</th>\n",
       "      <th>relig</th>\n",
       "      <th>family</th>\n",
       "      <th>we</th>\n",
       "      <th>death</th>\n",
       "      <th>friend</th>\n",
       "      <th>label</th>\n",
       "      <th>noun_count_percent</th>\n",
       "      <th>adj_count_percent</th>\n",
       "      <th>adv_count_percent</th>\n",
       "      <th>pro_count_percent</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>response</th>\n",
       "      <th>Response_emotion</th>\n",
       "      <th>valence_response</th>\n",
       "      <th>arousal_response</th>\n",
       "      <th>dominance_response</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>0.134328</td>\n",
       "      <td>0.104478</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>4.567164</td>\n",
       "      <td>0.068167</td>\n",
       "      <td>0.283582</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.71005</td>\n",
       "      <td>My 3 year old , that just finished readi...</td>\n",
       "      <td>joy</td>\n",
       "      <td>5.671111</td>\n",
       "      <td>4.181667</td>\n",
       "      <td>5.976667</td>\n",
       "      <td>['My', '3', 'year', 'old', ',', 'that', 'just'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>4.818182</td>\n",
       "      <td>0.219008</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.60115</td>\n",
       "      <td>How many verifiable lies has he told now ?...</td>\n",
       "      <td>joy</td>\n",
       "      <td>5.442857</td>\n",
       "      <td>3.635714</td>\n",
       "      <td>5.554286</td>\n",
       "      <td>['How', 'many', 'verifiable', 'lies', 'has', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>4.695652</td>\n",
       "      <td>0.204159</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>Maybe Docs just a scrub of a coach ... I...</td>\n",
       "      <td>anger</td>\n",
       "      <td>5.236250</td>\n",
       "      <td>4.210000</td>\n",
       "      <td>5.270000</td>\n",
       "      <td>['Maybe', 'Docs', 'just', 'a', 'scrub', 'of', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.272727</td>\n",
       "      <td>0.194215</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.19430</td>\n",
       "      <td>is just a cover up for the real hate insid...</td>\n",
       "      <td>anger</td>\n",
       "      <td>5.174000</td>\n",
       "      <td>4.290000</td>\n",
       "      <td>5.474000</td>\n",
       "      <td>['is', 'just', 'a', 'cover', 'up', 'for', 'the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NOT_SARCASM</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.47420</td>\n",
       "      <td>The irony being that he even has to ask ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>5.795000</td>\n",
       "      <td>3.630000</td>\n",
       "      <td>5.697500</td>\n",
       "      <td>['The', 'irony', 'being', 'that', 'he', 'even'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time  relativ  funct  pronoun  ipron  adverb  cogmech  excl  leisure  conj  \\\n",
       "0   6.0      6.0   19.0      9.0    5.0     3.0      9.0   2.0      2.0   5.0   \n",
       "1   1.0      1.0    6.0      1.0    0.0     1.0      2.0   0.0      0.0   0.0   \n",
       "2   0.0      0.0    7.0      1.0    1.0     1.0      4.0   1.0      2.0   0.0   \n",
       "3   0.0      4.0    9.0      0.0    0.0     1.0      3.0   1.0      0.0   0.0   \n",
       "4   0.0      0.0    6.0      2.0    1.0     1.0      1.0   0.0      0.0   0.0   \n",
       "\n",
       "   incl  verb  past  social  ppron    i  cause  humans  certain  achieve  \\\n",
       "0   2.0   2.0   1.0     7.0    4.0  1.0    3.0     1.0      1.0      4.0   \n",
       "1   0.0   2.0   1.0     2.0    1.0  0.0    0.0     0.0      2.0      0.0   \n",
       "2   1.0   2.0   0.0     1.0    0.0  0.0    0.0     0.0      0.0      1.0   \n",
       "3   1.0   2.0   0.0     0.0    0.0  0.0    0.0     0.0      1.0      0.0   \n",
       "4   0.0   3.0   0.0     2.0    1.0  0.0    1.0     0.0      0.0      0.0   \n",
       "\n",
       "   preps  tentat  space  affect  filler  posemo  present  they  shehe  negemo  \\\n",
       "0    3.0     1.0    1.0     4.0     1.0     3.0      1.0   2.0    1.0     1.0   \n",
       "1    1.0     0.0    0.0     3.0     0.0     2.0      1.0   0.0    1.0     1.0   \n",
       "2    3.0     0.0    0.0     0.0     0.0     0.0      2.0   0.0    0.0     0.0   \n",
       "3    4.0     0.0    4.0     1.0     0.0     0.0      2.0   0.0    0.0     1.0   \n",
       "4    1.0     0.0    0.0     0.0     0.0     0.0      2.0   0.0    1.0     0.0   \n",
       "\n",
       "   anger  quant  auxverb  article  insight  work  you  motion  discrep  \\\n",
       "0    1.0    0.0      0.0      0.0      0.0   0.0  0.0     0.0      0.0   \n",
       "1    1.0    1.0      1.0      1.0      0.0   0.0  0.0     0.0      0.0   \n",
       "2    0.0    0.0      0.0      2.0      1.0   1.0  0.0     0.0      0.0   \n",
       "3    1.0    0.0      1.0      3.0      0.0   0.0  0.0     0.0      0.0   \n",
       "4    0.0    0.0      2.0      0.0      0.0   0.0  0.0     0.0      0.0   \n",
       "\n",
       "   assent  inhib  home  percept  hear  anx  sad  see  money  negate  bio  \\\n",
       "0     0.0    0.0   0.0      0.0   0.0  0.0  0.0  0.0    0.0     0.0  0.0   \n",
       "1     0.0    0.0   0.0      0.0   0.0  0.0  0.0  0.0    0.0     0.0  0.0   \n",
       "2     0.0    0.0   0.0      0.0   0.0  0.0  0.0  0.0    0.0     0.0  0.0   \n",
       "3     0.0    0.0   0.0      0.0   0.0  0.0  0.0  0.0    0.0     0.0  0.0   \n",
       "4     0.0    0.0   0.0      0.0   0.0  0.0  0.0  0.0    0.0     0.0  0.0   \n",
       "\n",
       "   health  sexual  nonfl  future  swear  ingest  feel  number  body  relig  \\\n",
       "0     0.0     0.0    0.0     0.0    0.0     0.0   0.0     0.0   0.0    0.0   \n",
       "1     0.0     0.0    0.0     0.0    0.0     0.0   0.0     0.0   0.0    0.0   \n",
       "2     0.0     0.0    0.0     0.0    0.0     0.0   0.0     0.0   0.0    0.0   \n",
       "3     0.0     0.0    0.0     0.0    0.0     0.0   0.0     0.0   0.0    0.0   \n",
       "4     0.0     0.0    0.0     0.0    0.0     0.0   0.0     0.0   0.0    0.0   \n",
       "\n",
       "   family   we  death  friend        label  noun_count_percent  \\\n",
       "0     0.0  0.0    0.0     0.0  NOT_SARCASM            0.134328   \n",
       "1     0.0  0.0    0.0     0.0      SARCASM            0.181818   \n",
       "2     0.0  0.0    0.0     0.0      SARCASM            0.130435   \n",
       "3     0.0  0.0    0.0     0.0  NOT_SARCASM            0.045455   \n",
       "4     0.0  0.0    0.0     0.0  NOT_SARCASM            0.200000   \n",
       "\n",
       "   adj_count_percent  adv_count_percent  pro_count_percent  char_count  \\\n",
       "0           0.104478           0.089552           0.074627    4.567164   \n",
       "1           0.136364           0.045455           0.090909    4.818182   \n",
       "2           0.043478           0.043478           0.043478    4.695652   \n",
       "3           0.090909           0.045455           0.000000    4.272727   \n",
       "4           0.000000           0.133333           0.066667    4.200000   \n",
       "\n",
       "   word_density  punctuation_count  upper_case_word_count  vader_pos  \\\n",
       "0      0.068167           0.283582               0.074627      0.147   \n",
       "1      0.219008           0.363636               0.090909      0.215   \n",
       "2      0.204159           0.260870               0.173913      0.000   \n",
       "3      0.194215           0.318182               0.181818      0.000   \n",
       "4      0.280000           0.266667               0.200000      0.000   \n",
       "\n",
       "   vader_neg  vader_neu  vader_compound  \\\n",
       "0      0.134      0.719         0.71005   \n",
       "1      0.131      0.654         0.60115   \n",
       "2      0.000      1.000         0.50000   \n",
       "3      0.200      0.800         0.19430   \n",
       "4      0.091      0.909         0.47420   \n",
       "\n",
       "                                            response Response_emotion  \\\n",
       "0        My 3 year old , that just finished readi...              joy   \n",
       "1      How many verifiable lies has he told now ?...              joy   \n",
       "2        Maybe Docs just a scrub of a coach ... I...            anger   \n",
       "3      is just a cover up for the real hate insid...            anger   \n",
       "4        The irony being that he even has to ask ...            anger   \n",
       "\n",
       "   valence_response  arousal_response  dominance_response  \\\n",
       "0          5.671111          4.181667            5.976667   \n",
       "1          5.442857          3.635714            5.554286   \n",
       "2          5.236250          4.210000            5.270000   \n",
       "3          5.174000          4.290000            5.474000   \n",
       "4          5.795000          3.630000            5.697500   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  ['My', '3', 'year', 'old', ',', 'that', 'just'...  \n",
       "1  ['How', 'many', 'verifiable', 'lies', 'has', '...  \n",
       "2  ['Maybe', 'Docs', 'just', 'a', 'scrub', 'of', ...  \n",
       "3  ['is', 'just', 'a', 'cover', 'up', 'for', 'the...  \n",
       "4  ['The', 'irony', 'being', 'that', 'he', 'even'...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##TODO\n",
    "\n",
    "csv_file = '/Users/swcam/Documents/GitHub/Sarcasm/Final_data/liwc_response_test.csv'\n",
    "#csv_file = '/Users/swcam/Documents/GitHub/Sarcasm/Final_Features_test_data'\n",
    "Test_df = pd.read_csv(csv_file)\n",
    "Test_df = Test_df.loc[:, ~Test_df.columns.str.contains('^Unnamed')]\n",
    "# print out the first few rows of data info\n",
    "Test_df.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 83)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Train_df\n",
    "\n",
    "X_test= Test_df\n",
    "\n",
    "y_train= Train_df['label']\n",
    "\n",
    "y_test = Test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import preprocessing\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}') # word that appears 1 or more times\n",
    "count_vect.fit(Train_df['response'])\n",
    "count_vect.fit(Test_df['response'])\n",
    "# to show resulting vocabulary; the numbers are not counts, they are the position in the sparse vector.\n",
    "count_vect.vocabulary_\n",
    "\n",
    "# transform the training and validation data using count vectorizer object: doc x term\n",
    "xtrain_count =  count_vect.transform(Train_df['response']) \n",
    "xvalid_count =  count_vect.transform(Test_df['response'])\n",
    "\n",
    "xvalid_count= xvalid_count.toarray()\n",
    "xtrain_count= xtrain_count.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word level tfidf Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000) # considers the top 5000 most frequent features\n",
    "tfidf_vect.fit(Train_df['response'])\n",
    "tfidf_vect.fit(Test_df['response'])\n",
    "\n",
    "\n",
    "tfidf_train = tfidf_vect.transform(Train_df['response'])\n",
    "tfidf_test = tfidf_vect.transform(Test_df['response'])\n",
    "\n",
    "tfidf_train = tfidf_train.toarray()\n",
    "tfidf_test = tfidf_test.toarray()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ngram level tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(Train_df['response'])\n",
    "tfidf_vect_ngram.fit(Test_df['response'])\n",
    "\n",
    "tfidf_ngram_train =  tfidf_vect_ngram.transform(Train_df['response'])\n",
    "tfidf_ngram_test =  tfidf_vect_ngram.transform(Test_df['response'])\n",
    "\n",
    "tfidf_ngram_train = tfidf_ngram_train.toarray()\n",
    "tfidf_ngram_test = tfidf_ngram_test.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character level tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swcam\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
      "C:\\Users\\swcam\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "  ### characters level tf-idf\n",
    "\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(Train_df['response'])\n",
    "tfidf_vect_ngram_chars.fit(Test_df['response'])\n",
    "\n",
    "\n",
    "tfidf_ngram_chars_train =  tfidf_vect_ngram_chars.transform(Train_df['response']) \n",
    "\n",
    "tfidf_ngram_chars_test =  tfidf_vect_ngram_chars.transform(Test_df['response'])\n",
    "                                   \n",
    "\n",
    "                                   \n",
    "tfidf_ngram_chars_train =  tfidf_ngram_chars_train.toarray()\n",
    "\n",
    "tfidf_ngram_chars_test = tfidf_ngram_chars_test.toarray()\n",
    "                                           \n",
    "                                   \n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "# fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "    return metrics.accuracy_score(predictions, y_test),metrics.precision_score(predictions, y_test),metrics.recall_score(predictions, y_test),metrics.f1_score(predictions, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results on Test data running only count vectors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  word level tfidf feature NB, :  A: 0.58 P: 0.67 R: 0.56 F1: 0.61\n",
      " Count vector feature NB, :  A: 0.59 P: 0.64 R: 0.58 F1: 0.61\n",
      " ngram word level tfidf feature NB, :  A: 0.58 P: 0.67 R: 0.56 F1: 0.61\n",
      " ngram char level tfidf feature NB, :  A: 0.6 P: 0.78 R: 0.57 F1: 0.66\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "accuracy, precision, recall,f1  = train_model(naive_bayes.GaussianNB(), tfidf_ngram_train , y_train, tfidf_ngram_test)\n",
    "print (\"  word level tfidf feature NB, : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n",
    "\n",
    "accuracy, precision, recall,f1  = train_model(naive_bayes.GaussianNB(), xtrain_count , y_train, xvalid_count)\n",
    "print (\" Count vector feature NB, : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n",
    "\n",
    "accuracy, precision, recall,f1  = train_model(naive_bayes.GaussianNB(), tfidf_ngram_train , y_train, tfidf_ngram_test)\n",
    "print (\" ngram word level tfidf feature NB, : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n",
    "\n",
    "accuracy, precision, recall,f1  = train_model(naive_bayes.GaussianNB(), tfidf_ngram_chars_train , y_train, tfidf_ngram_chars_test)\n",
    "print (\" ngram char level tfidf feature NB, : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word level tfidf feature RF :  A: 0.58 P: 0.82 R: 0.55 F1: 0.66\n",
      "Count vector feature RF, :  A: 0.62 P: 0.71 R: 0.6 F1: 0.65\n",
      "ngram word level tfidf feature RF, :  A: 0.58 P: 0.82 R: 0.55 F1: 0.66\n",
      "ngram char level tfidf feature RF, :  A: 0.64 P: 0.74 R: 0.61 F1: 0.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "accuracy, precision, recall,f1  = train_model(RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0), tfidf_ngram_train , y_train, tfidf_ngram_test)\n",
    "print (\"word level tfidf feature RF : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n",
    "\n",
    "accuracy, precision, recall,f1  = train_model(RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0), xtrain_count , y_train, xvalid_count)\n",
    "print (\"Count vector feature RF, : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n",
    "\n",
    "accuracy, precision, recall,f1  = train_model(RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0), tfidf_ngram_train , y_train, tfidf_ngram_test)\n",
    "print (\"ngram word level tfidf feature RF, : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n",
    "\n",
    "accuracy, precision, recall,f1  = train_model(RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0), tfidf_ngram_chars_train , y_train, tfidf_ngram_chars_test)\n",
    "print (\"ngram char level tfidf feature RF, : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Svm:  A: 0.65 P: 0.66 R: 0.65 F1: 0.66\n",
      "word level tfidf feature RF :  A: 0.62 P: 0.75 R: 0.6 F1: 0.67\n",
      "Count vector feature RF, :  A: 0.65 P: 0.66 R: 0.65 F1: 0.66\n",
      "ngram word level tfidf feature RF, :  A: 0.62 P: 0.75 R: 0.6 F1: 0.67\n",
      "ngram char level tfidf feature RF, :  A: 0.69 P: 0.77 R: 0.66 F1: 0.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "accuracy, precision, recall,f1  = train_model(svm.SVC(), tfidf_ngram_train , y_train, tfidf_ngram_test)\n",
    "print (\"word level tfidf feature SVM : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n",
    "\n",
    "accuracy, precision, recall,f1  = train_model(svm.SVC(), xtrain_count , y_train, xvalid_count)\n",
    "print (\"Count vector feature SVM, : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n",
    "\n",
    "accuracy, precision, recall,f1  = train_model(svm.SVC(), tfidf_ngram_train , y_train, tfidf_ngram_test)\n",
    "print (\"ngram word level tfidf feature SVM, : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n",
    "\n",
    "accuracy, precision, recall,f1  = train_model(svm.SVC(), tfidf_ngram_chars_train , y_train, tfidf_ngram_chars_test)\n",
    "print (\"ngram char level tfidf feature SVM, : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_count_features_train = np.column_stack([xtrain_count,tfidf_ngram_train,tfidf_ngram_train,tfidf_ngram_chars_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_count_features_test = np.column_stack([tfidf_ngram_test,xvalid_count,tfidf_ngram_test,tfidf_ngram_chars_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing only count vector combination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all count features combo RF :  A: 0.63 P: 0.72 R: 0.61 F1: 0.66\n",
      " ngram char level tfidf feature NB, :  A: 0.51 P: 0.65 R: 0.51 F1: 0.57\n",
      "all count features combo SVM :  A: 0.55 P: 0.58 R: 0.55 F1: 0.57\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall,f1  = train_model(RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0), all_count_features_train, y_train, all_count_features_test)\n",
    "print (\"all count features combo RF : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n",
    "\n",
    "accuracy, precision, recall,f1  = train_model(naive_bayes.GaussianNB(), all_count_features_train , y_train, all_count_features_test)\n",
    "print (\" all count features combo NB, : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n",
    "\n",
    "accuracy, precision, recall,f1  = train_model(svm.SVC(), all_count_features_train , y_train, all_count_features_test)\n",
    "print (\"all count features combo SVM : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Linguistic Features to Count Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop(['tokenized_text','label','response'], axis=1)\n",
    "X_train = X_train.drop(['tokenized_text','label','response'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['Response_emotion'] = X_test['Response_emotion'].astype('category').cat.codes\n",
    "X_train['Response_emotion'] = X_train['Response_emotion'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL Linguistic Features + ALL count features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_train = np.column_stack([all_count_features_train, X_train])\n",
    "all_features_test = np.column_stack([all_count_features_test, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linguistic + count features RF :  A: 0.65 P: 0.7 R: 0.64 F1: 0.67\n",
      "Linguistic + count features NB, :  A: 0.6 P: 0.7 R: 0.59 F1: 0.64\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall,f1  = train_model(RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0), all_features_train, y_train, all_features_test)\n",
    "print (\"Linguistic + count features RF : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n",
    "\n",
    "accuracy, precision, recall,f1  = train_model(naive_bayes.GaussianNB(), all_features_train , y_train, all_features_test)\n",
    "print (\"Linguistic + count features NB, : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linguistic + count features SVM :  A: 0.57 P: 0.57 R: 0.57 F1: 0.57\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall,f1  = train_model(svm.SVC(), all_features_train , y_train, all_features_test)\n",
    "print (\"Linguistic + count features SVM : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Linguistic Features + Ngram Character tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ling_ngram_chars_train = np.column_stack([tfidf_ngram_chars_train, X_train])\n",
    "all_ling_ngram_chars_test = np.column_stack([tfidf_ngram_chars_test, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linguistic + count features RF :  A: 0.65 P: 0.7 R: 0.64 F1: 0.67\n",
      "Linguistic + count features NB, :  A: 0.6 P: 0.7 R: 0.59 F1: 0.64\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall,f1  = train_model(RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0), all_ling_ngram_chars_train, y_train, all_ling_ngram_chars_test)\n",
    "print (\"all Linguistic Features + Ngram Char level tfidfRF : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n",
    "\n",
    "accuracy, precision, recall,f1  = train_model(naive_bayes.GaussianNB(), all_ling_ngram_chars_train , y_train, all_ling_ngram_chars_test)\n",
    "print (\"all Linguistic Features + Ngram Char level tfidf NB, : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all Linguistic Features + Ngram Char level tfidf SVM :  A: 0.57 P: 0.57 R: 0.57 F1: 0.57\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall,f1  = train_model(svm.SVC(), all_ling_ngram_chars_train , y_train, all_ling_ngram_chars_test)\n",
    "print (\"all Linguistic Features + Ngram Char level tfidf SVM : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>funct</th>\n",
       "      <th>auxverb</th>\n",
       "      <th>present</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>ipron</th>\n",
       "      <th>cogmech</th>\n",
       "      <th>certain</th>\n",
       "      <th>ppron</th>\n",
       "      <th>you</th>\n",
       "      <th>social</th>\n",
       "      <th>affect</th>\n",
       "      <th>posemo</th>\n",
       "      <th>conj</th>\n",
       "      <th>tentat</th>\n",
       "      <th>excl</th>\n",
       "      <th>future</th>\n",
       "      <th>discrep</th>\n",
       "      <th>past</th>\n",
       "      <th>motion</th>\n",
       "      <th>relativ</th>\n",
       "      <th>space</th>\n",
       "      <th>preps</th>\n",
       "      <th>incl</th>\n",
       "      <th>adverb</th>\n",
       "      <th>insight</th>\n",
       "      <th>shehe</th>\n",
       "      <th>achieve</th>\n",
       "      <th>negemo</th>\n",
       "      <th>anger</th>\n",
       "      <th>they</th>\n",
       "      <th>cause</th>\n",
       "      <th>article</th>\n",
       "      <th>money</th>\n",
       "      <th>work</th>\n",
       "      <th>percept</th>\n",
       "      <th>hear</th>\n",
       "      <th>swear</th>\n",
       "      <th>time</th>\n",
       "      <th>negate</th>\n",
       "      <th>leisure</th>\n",
       "      <th>death</th>\n",
       "      <th>number</th>\n",
       "      <th>see</th>\n",
       "      <th>sad</th>\n",
       "      <th>quant</th>\n",
       "      <th>anx</th>\n",
       "      <th>assent</th>\n",
       "      <th>bio</th>\n",
       "      <th>health</th>\n",
       "      <th>filler</th>\n",
       "      <th>body</th>\n",
       "      <th>friend</th>\n",
       "      <th>sexual</th>\n",
       "      <th>we</th>\n",
       "      <th>home</th>\n",
       "      <th>feel</th>\n",
       "      <th>inhib</th>\n",
       "      <th>humans</th>\n",
       "      <th>i</th>\n",
       "      <th>family</th>\n",
       "      <th>relig</th>\n",
       "      <th>nonfl</th>\n",
       "      <th>ingest</th>\n",
       "      <th>label</th>\n",
       "      <th>noun_count_percent</th>\n",
       "      <th>adj_count_percent</th>\n",
       "      <th>adv_count_percent</th>\n",
       "      <th>pro_count_percent</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>response</th>\n",
       "      <th>Response_emotion</th>\n",
       "      <th>valence_response</th>\n",
       "      <th>arousal_response</th>\n",
       "      <th>dominance_response</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>4.862069</td>\n",
       "      <td>0.167658</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.87530</td>\n",
       "      <td>I don't get this .. obviously you do car...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>6.222500</td>\n",
       "      <td>3.695000</td>\n",
       "      <td>5.965000</td>\n",
       "      <td>['I', 'do', \"n't\", 'get', 'this', '..', 'obvio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.11985</td>\n",
       "      <td>trying to protest about . Talking about hi...</td>\n",
       "      <td>anger</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>3.713333</td>\n",
       "      <td>5.733333</td>\n",
       "      <td>['trying', 'to', 'protest', 'about', '.', 'Tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>5.777778</td>\n",
       "      <td>0.320988</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.27130</td>\n",
       "      <td>He makes an insane about of money from t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>5.246667</td>\n",
       "      <td>5.223333</td>\n",
       "      <td>5.426667</td>\n",
       "      <td>['He', 'makes', 'an', 'insane', 'about', 'of',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>0.243056</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.24470</td>\n",
       "      <td>Meanwhile Trump won't even release his SAT...</td>\n",
       "      <td>anger</td>\n",
       "      <td>5.661111</td>\n",
       "      <td>4.428889</td>\n",
       "      <td>5.907778</td>\n",
       "      <td>['Meanwhile', 'Trump', 'wo', \"n't\", 'even', 'r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SARCASM</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>5.575758</td>\n",
       "      <td>0.168962</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.83525</td>\n",
       "      <td>Pretty Sure the Anti-Lincoln Crowd Claimed...</td>\n",
       "      <td>joy</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>['Pretty', 'Sure', 'the', 'Anti-Lincoln', 'Cro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   verb  funct  auxverb  present  pronoun  ipron  cogmech  certain  ppron  \\\n",
       "0     7     13        3        5        5      1        6        1      4   \n",
       "1     2     11        1        2        5      1        3        0      4   \n",
       "2     1      5        0        1        0      0        1        0      0   \n",
       "3     3      9        1        0        4      0        2        1      4   \n",
       "4     0      5        0        0        0      0        0        0      0   \n",
       "\n",
       "   you  social  affect  posemo  conj  tentat  excl  future  discrep  past  \\\n",
       "0    3       4       2       2     2       1     1       1        1     1   \n",
       "1    0       4       1       0     2       0     0       0        0     0   \n",
       "2    0       0       0       0     0       0     0       0        0     0   \n",
       "3    0       5       1       0     1       0     0       0        0     3   \n",
       "4    0       0       0       0     0       0     0       0        0     0   \n",
       "\n",
       "   motion  relativ  space  preps  incl  adverb  insight  shehe  achieve  \\\n",
       "0       1        2      1      2     2       1        1      1        0   \n",
       "1       0        0      0      3     2       2        0      2        1   \n",
       "2       0        0      0      3     0       1        0      0        0   \n",
       "3       0        1      0      0     1       2        0      3        0   \n",
       "4       0        2      2      2     0       1        0      0        0   \n",
       "\n",
       "   negemo  anger  they  cause  article  money  work  percept  hear  swear  \\\n",
       "0       0      0     0      0        0      0     0        0     0      0   \n",
       "1       1      1     2      1        0      0     0        0     0      0   \n",
       "2       0      0     0      1        2      1     0        0     0      0   \n",
       "3       1      1     1      0        1      0     3        1     1      1   \n",
       "4       0      0     0      0        2      0     0        0     0      0   \n",
       "\n",
       "   time  negate  leisure  death  number  see  sad  quant  anx  assent  bio  \\\n",
       "0     0       0        0      0       0    0    0      0    0       0    0   \n",
       "1     0       0        0      0       0    0    0      0    0       0    0   \n",
       "2     0       0        0      0       0    0    0      0    0       0    0   \n",
       "3     1       0        0      0       0    0    0      0    0       0    0   \n",
       "4     0       0        0      0       0    0    0      0    0       0    0   \n",
       "\n",
       "   health  filler  body  friend  sexual  we  home  feel  inhib  humans  i  \\\n",
       "0       0       0     0       0       0   0     0     0      0       0  0   \n",
       "1       0       0     0       0       0   0     0     0      0       0  0   \n",
       "2       0       0     0       0       0   0     0     0      0       0  0   \n",
       "3       0       0     0       0       0   0     0     0      0       0  0   \n",
       "4       0       0     0       0       0   0     0     0      0       0  0   \n",
       "\n",
       "   family  relig  nonfl  ingest    label  noun_count_percent  \\\n",
       "0       0      0      0       0  SARCASM            0.310345   \n",
       "1       0      0      0       0  SARCASM            0.250000   \n",
       "2       0      0      0       0  SARCASM            0.055556   \n",
       "3       0      0      0       0  SARCASM            0.208333   \n",
       "4       0      0      0       0  SARCASM            0.060606   \n",
       "\n",
       "   adj_count_percent  adv_count_percent  pro_count_percent  char_count  \\\n",
       "0           0.034483           0.172414           0.172414    4.862069   \n",
       "1           0.000000           0.000000           0.166667    5.000000   \n",
       "2           0.000000           0.000000           0.055556    5.777778   \n",
       "3           0.041667           0.166667           0.166667    5.833333   \n",
       "4           0.030303           0.030303           0.030303    5.575758   \n",
       "\n",
       "   word_density  punctuation_count  upper_case_word_count  vader_pos  \\\n",
       "0      0.167658           0.379310               0.137931      0.204   \n",
       "1      0.208333           0.166667               0.125000      0.000   \n",
       "2      0.320988           0.333333               0.222222      0.000   \n",
       "3      0.243056           0.166667               0.125000      0.000   \n",
       "4      0.168962           0.393939               0.090909      0.193   \n",
       "\n",
       "   vader_neg  vader_neu  vader_compound  \\\n",
       "0      0.000      0.796         0.87530   \n",
       "1      0.256      0.744         0.11985   \n",
       "2      0.176      0.824         0.27130   \n",
       "3      0.130      0.870         0.24470   \n",
       "4      0.000      0.807         0.83525   \n",
       "\n",
       "                                            response Response_emotion  \\\n",
       "0        I don't get this .. obviously you do car...          sadness   \n",
       "1      trying to protest about . Talking about hi...            anger   \n",
       "2        He makes an insane about of money from t...            anger   \n",
       "3      Meanwhile Trump won't even release his SAT...            anger   \n",
       "4      Pretty Sure the Anti-Lincoln Crowd Claimed...              joy   \n",
       "\n",
       "   valence_response  arousal_response  dominance_response  \\\n",
       "0          6.222500          3.695000            5.965000   \n",
       "1          5.190000          3.713333            5.733333   \n",
       "2          5.246667          5.223333            5.426667   \n",
       "3          5.661111          4.428889            5.907778   \n",
       "4          5.000000          5.000000            5.000000   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  ['I', 'do', \"n't\", 'get', 'this', '..', 'obvio...  \n",
       "1  ['trying', 'to', 'protest', 'about', '.', 'Tal...  \n",
       "2  ['He', 'makes', 'an', 'insane', 'about', 'of',...  \n",
       "3  ['Meanwhile', 'Trump', 'wo', \"n't\", 'even', 'r...  \n",
       "4  ['Pretty', 'Sure', 'the', 'Anti-Lincoln', 'Cro...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Linguistic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHAP\n",
    "\n",
    "#Train_df_select = Train_df[['vader_compound', 'valence_response', 'time','word_density','noun_count_percent','dominance_response','you','upper_case_word_count','adj_count_percent','char_count','vader_neu','arousal_response','funct','pro_count_percent','Response_emotion','ppron','relativ','adv_count_percent']]\n",
    "#Test_df_select = Test_df[['vader_compound', 'valence_response', 'time','word_density','noun_count_percent','dominance_response','you','upper_case_word_count','adj_count_percent','char_count','vader_neu','arousal_response','funct','pro_count_percent','Response_emotion','ppron','relativ','adv_count_percent']]\n",
    "\n",
    "#Turf\n",
    "#Train_df_select= Train_df[['Response_emotion','word_density','valence_response','vader_neg','vader_neu','noun_count_percent','affect','funct','negemo','vader_pos','adv_count_percent','relativ','vader_compound','char_count','posemo','dominance_response','pro_count_percent','leisure','anger','cause']].copy()\n",
    "#Test_df_select= Test_df[['Response_emotion','word_density','valence_response','vader_neg','vader_neu','noun_count_percent','affect','funct','negemo','vader_pos','adv_count_percent','relativ','vader_compound','char_count','posemo','dominance_response','pro_count_percent','leisure','anger','cause']].copy()\n",
    "\n",
    "#Relief\n",
    "Train_df_select = Train_df[['Response_emotion','valence_response','vader_neg','word_density','vader_compound','vader_neu','noun_count_percent','negemo','vader_pos','affect','dominance_response','char_count','leisure','funct','posemo','negate','ppron','anger','relativ','money']].copy()\n",
    "\n",
    "Test_df_select = Test_df[['Response_emotion','valence_response','vader_neg','word_density','vader_compound','vader_neu','noun_count_percent','negemo','vader_pos','affect','dominance_response','char_count','leisure','funct','posemo','negate','ppron','anger','relativ','money']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_df_select ['Response_emotion'] = Train_df_select ['Response_emotion'].astype('category').cat.codes\n",
    "Test_df_select['Response_emotion'] = Test_df_select['Response_emotion'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select Linguistic Features RF :  A: 0.59 P: 0.55 R: 0.6 F1: 0.57\n",
      "Select Linguistic Features NB, :  A: 0.59 P: 0.61 R: 0.59 F1: 0.6\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall,f1  = train_model(RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0), Train_df_select, y_train, Test_df_select)\n",
    "print (\"Select Linguistic Features RF : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n",
    "\n",
    "accuracy, precision, recall,f1  = train_model(naive_bayes.GaussianNB(), Train_df_select, y_train, Test_df_select)\n",
    "print (\"Select Linguistic Features NB, : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select Linguistic Features SVM :  A: 0.58 P: 0.42 R: 0.62 F1: 0.5\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall,f1  = train_model(svm.SVC(), Train_df_select, y_train, Test_df_select)\n",
    "print (\"Select Linguistic Features SVM : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Linguistic Features + All counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_ling_all_count_train = np.column_stack([all_count_features_train, Train_df_select])\n",
    "select_ling_all_count_test = np.column_stack([all_count_features_test, Test_df_select])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select Linguistic + ALL counts RF :  A: 0.65 P: 0.73 R: 0.63 F1: 0.68\n",
      "Select Linguistic + ALL counts NB, :  A: 0.51 P: 0.65 R: 0.51 F1: 0.57\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall,f1  = train_model(RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0), select_ling_all_count_train, y_train, select_ling_all_count_test)\n",
    "print (\"Select Linguistic + ALL counts RF : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n",
    "\n",
    "accuracy, precision, recall,f1  = train_model(naive_bayes.GaussianNB(), select_ling_all_count_train, y_train, select_ling_all_count_test)\n",
    "print (\"Select Linguistic + ALL counts NB, : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select Linguistic + ALL counts SVM :  A: 0.59 P: 0.76 R: 0.57 F1: 0.65\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall,f1  = train_model(svm.SVC(), select_ling_all_count_train, y_train, select_ling_all_count_test)\n",
    "print (\"Select Linguistic + ALL counts SVM : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Linguistic Features + ngram char tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_ling_ngram_char_train = np.column_stack([tfidf_ngram_chars_train, Train_df_select])\n",
    "select_ling_ngram_char_test = np.column_stack([tfidf_ngram_chars_test, Test_df_select])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select Linguistic + tfidf ngram char RF :  A: 0.64 P: 0.68 R: 0.63 F1: 0.65\n",
      "Select Linguistic + tfidf ngram char NB, :  A: 0.6 P: 0.7 R: 0.58 F1: 0.64\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall,f1  = train_model(RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0), select_ling_ngram_char_train, y_train, select_ling_ngram_char_test)\n",
    "print (\"Select Linguistic + tfidf ngram char RF : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n",
    "\n",
    "accuracy, precision, recall,f1  = train_model(naive_bayes.GaussianNB(), select_ling_ngram_char_train, y_train, select_ling_ngram_char_test)\n",
    "print (\"Select Linguistic + tfidf ngram char NB, : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select Linguistic + tfidf ngram char SVM, :  A: 0.59 P: 0.43 R: 0.63 F1: 0.51\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall,f1  = train_model(svm.SVC(), select_ling_ngram_char_train, y_train, select_ling_ngram_char_test)\n",
    "print (\"Select Linguistic + tfidf ngram char SVM, : \", \"A:\", round(accuracy,2), \"P:\", round(precision,2), \"R:\", round(recall,2), \"F1:\", round(f1,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swcam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\swcam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\swcam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\swcam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\swcam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\swcam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\swcam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\swcam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\swcam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\swcam\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\swcam\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\swcam\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\swcam\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\swcam\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\swcam\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\swcam\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\swcam\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\swcam\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\swcam\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\swcam\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0,max_iter=500),\n",
    "    GaussianNB(),\n",
    "    svm.SVC(),\n",
    "]\n",
    "CV = 10\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "  model_name = model.__class__.__name__\n",
    "  accuracies = cross_val_score(model, select_ling_all_count_train, y_train, scoring='accuracy', cv=CV)\n",
    "  for fold_idx, accuracy in enumerate(accuracies):\n",
    "    entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "import seaborn as sns\n",
    "sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
    "              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name\n",
       "GaussianNB                0.6720\n",
       "LinearSVC                 0.7404\n",
       "LogisticRegression        0.7622\n",
       "MultinomialNB             0.7526\n",
       "RandomForestClassifier    0.7252\n",
       "SVC                       0.7168\n",
       "Name: accuracy, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df.groupby('model_name').accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name\n",
       "GaussianNB                0.712\n",
       "LinearSVC                 0.794\n",
       "LogisticRegression        0.808\n",
       "MultinomialNB             0.816\n",
       "RandomForestClassifier    0.796\n",
       "SVC                       0.796\n",
       "Name: accuracy, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df.groupby('model_name').accuracy.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name\n",
       "GaussianNB                0.524\n",
       "LinearSVC                 0.590\n",
       "LogisticRegression        0.582\n",
       "MultinomialNB             0.578\n",
       "RandomForestClassifier    0.566\n",
       "SVC                       0.580\n",
       "Name: accuracy, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df.groupby('model_name').accuracy.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
